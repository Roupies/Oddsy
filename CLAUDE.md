# CLAUDE.md

This file provides guidance to Claude Code when working with the **Oddsy** repository.

## Project Overview

**Oddsy** is a Premier League football match prediction project that uses machine learning to predict Home/Draw/Away results. The project focuses on sophisticated feature engineering and data analysis of Premier League matches from 2019-2024.

## Project Objectives

**Primary Goal:** Build a machine learning model that predicts football match outcomes (H/D/A) better than naive baselines.

**Performance Targets:**
- **Minimum Acceptable:** > 43.6% accuracy (beat majority class baseline)
- **Good Model:** > 50% accuracy  
- **Excellent Model:** > 55% accuracy (industry-competitive)

**Key Baselines to Beat:**
- Random prediction (33/33/33): 33.3%
- Always predict Home: 43.6% 
- Weighted random by distribution: 35.4%

**Business Context:** Real Premier League distribution is naturally imbalanced (H: 43.6%, A: 33.4%, D: 23.0%) - this reflects actual football dynamics, not a data quality issue.

## Architecture & Data Pipeline

The project follows a clear data processing pipeline:

1. **Raw Data** (`data/raw/`) - Original Premier League CSV files
2. **Cleaned Data** (`data/cleaned/`) - Processed and cleaned datasets
3. **Processed Data** (`data/processed/`) - Feature-engineered datasets ready for ML
4. **Models** (`models/`) - Versioned trained models with metadata
5. **Evaluation** (`evaluation/`) - Performance reports & metrics history

## Current Production Status - v2.4 HYBRID CASCADE MODEL (September 2, 2025)

### **ğŸ¯ PRODUCTION MODEL: 53% ACCURACY + 34% DRAW RECALL (BALANCED & VALIDATED)**

**âœ… HYBRID CASCADE BREAKTHROUGH** - Draw prediction problem solved with validated architecture

**Revolutionary Approach: Two-Stage Cascade Model**
- **Stage 1:** Draw vs Non-Draw detector (binary classification with SMOTE oversampling)
- **Stage 2:** Home vs Away classifier (for non-draws only)
- **Threshold:** 0.4 probability for draw detection (optimized balance)
- **Architecture:** Fully independent stages prevent cascade-specific data leakage

**Production Model (v2.4 Hybrid Cascade):**
- **Algorithm:** Dual RandomForest cascade with hyperparameter optimization + Isotonic calibration
- **Performance:** 53.0% global accuracy + 34.4% draw recall (vs baseline 55% + 2% draw recall)
- **Features:** Same 10 validated features as v2.3 (no additional leakage risk)
- **Trade-off:** -2pp global accuracy for +32pp draw recall improvement
- **F1-Macro:** 0.507 vs 0.429 baseline (+18% improvement in balanced performance)

**Critical Validation Completed:**
- **5/5 Integrity Tests Passed:** Temporal, feature correlation, cross-validation, cascade-specific leakage, time consistency
- **No Data Leakage Detected:** Comprehensive validation confirms clean architecture
- **Stable Performance:** 46.4% Â± 4.0% cross-validation, 48.1% Â± 2.0% across seasons
- **Realistic Components:** Stage 1 (68% accuracy, 24% draw recall), Stage 2 (73% H vs A accuracy)
- **Model File:** `models/randomforest_corrected_model_2025_09_02_113228.joblib`
- **Dataset:** `data/processed/v13_xg_corrected_features_latest.csv`
- **Validation:** Comprehensive integrity verification suite (ALL tests passed)

### **ğŸ¯ v2.3 Final Feature Set (10 Optimized Features)**

**Production Feature Set (Corrected & Validated - 55.0% accuracy):**

1. **`elo_diff_normalized`** (15.5%) - Team strength difference (core predictor)
2. **`market_entropy_norm`** (12.5%) - Market uncertainty (key signal)
3. **`home_xg_eff_10`** (11.4%) - Home xG efficiency (10-match, corrected bounds)
4. **`away_xg_eff_10`** (10.8%) - Away xG efficiency (10-match, corrected bounds)
5. **`shots_diff_normalized`** (10.5%) - Attacking intent difference
6. **`corners_diff_normalized`** (9.4%) - Pressure/possession proxy
7. **`matchday_normalized`** (8.2%) - Season progression context
8. **`form_diff_normalized`** (7.7%) - Recent form difference (5-match window)
9. **`h2h_score`** (7.4%) - Head-to-head historical performance
10. **`away_goals_sum_5`** (6.5%) - Away recent scoring record

**Key Feature Insights:**
- **xG Integration Success:** Corrected xG efficiency features provide significant predictive value (22.2% combined importance)
- **Data Leakage Resolution:** Emergency fix eliminated impossible efficiency values (>11.0) with realistic bounds [0.3, 3.0]
- **Market Intelligence:** `market_entropy_norm` remains critical second-most important feature
- **Balanced Portfolio:** Mix of strength (Elo), form, market sentiment, and xG efficiency

**Phase 2.1 xG Integration Results (HISTORICAL - SUPERSEDED):**
```
Phase 2.1.1: Build xG features          âœ… 42 xG features with temporal safety
Phase 2.1.2: Progressive testing        âœ… Found data leakage in 56.3% result  
Phase 2.1.3: Investigate & validate     âœ… Clean features created, leakage eliminated
Phase 2.1.4: Address train/test gap     âœ… Model complexity issue resolved
Phase 2.1.5: Production model           âœ… 54.2% honest performance achieved
```

**Key Discovery: xG Features Don't Add Value**
- **Traditional features:** 54.2% accuracy
- **xG enhanced features:** 54.2% accuracy (identical, no improvement)
- **xG only features:** 50.5% accuracy (insufficient)
- **Conclusion:** Clean xG features provide no predictive benefit over traditional metrics

### **ğŸ“Š v2.3 Production Performance (VALIDATED)**

**Current Status & Business Assessment:**
âœ… **"EXCELLENT MODEL"** - 55.0% beats all targets (Random 33.3%, Majority 43.6%, Good 52%, Excellent 55%)  
ğŸ¯ **TARGET ACHIEVED** - 55.0% exactly meets excellent target  
ğŸ† **VALIDATION SUCCESS** - Comprehensive integrity verification (all tests passed)  
ğŸš€ **PRODUCTION READY** - Fully validated baseline for deployment

**Benchmark Comparisons:**
- âœ… **Random Baseline (33.3%):** +21.7pp  
- âœ… **Majority Class (43.6%):** +11.4pp
- âœ… **Good Target (52%):** +3.0pp
- âœ… **Excellent Target (55%):** +0.0pp (TARGET ACHIEVED!)
- âŒ **Elite Target (60%):** -5.0pp (future development target)

**Classification Performance (Validated):**
- **Home Wins:** 56% precision, 77% recall, 64% F1-score
- **Away Wins:** 55% precision, 67% recall, 60% F1-score  
- **Draws:** 33% precision, 2% recall, 4% F1-score (still challenging but model aware)

**Model Health Metrics:**
- **Integrity Validation:** 5/5 comprehensive tests passed
- **Cross-validation:** 53.1% Â± 1.7% (excellent stability)
- **Feature Leakage:** None detected (max future correlation: 0.037)
- **Temporal Integrity:** 89-day train/test gap, no overlap

### **ğŸ¯ v2.4 Cascade Feature Set (10 Validated Features)**

**Production Feature Set (Cascade Architecture - 53% global + 34% draw recall):**

1. **`elo_diff_normalized`** - Team strength difference (core predictor) - **15.5% importance**
2. **`market_entropy_norm`** - Market uncertainty signal - **12.5% importance**
3. **`home_xg_eff_10`** - Home team xG efficiency (10-match rolling, corrected) - **11.4% importance**
4. **`away_xg_eff_10`** - Away team xG efficiency (10-match rolling, corrected) - **10.8% importance**
5. **`shots_diff_normalized`** - Shot differential proxy - **10.5% importance**
6. **`corners_diff_normalized`** - Pressure/possession proxy - **9.4% importance**
7. **`matchday_normalized`** - Season progression context - **8.2% importance**
8. **`form_diff_normalized`** - Recent form difference (5-match window) - **7.7% importance**
9. **`h2h_score`** - Head-to-head historical performance - **7.4% importance**
10. **`away_goals_sum_5`** - Away scoring form context - **6.5% importance**

**Key Cascade Insights:**
- **Hybrid Architecture:** 2-stage cascade with independent RandomForest classifiers
- **Stage 1 (Draw Detection):** Binary classifier with SMOTE oversampling (Draw vs Non-Draw)
- **Stage 2 (H vs A):** Standard classifier for non-draw matches only
- **Optimal Threshold:** 0.4 probability for draw prediction (balanced precision/recall)
- **xG Integration Success:** Corrected xG efficiency features contribute meaningfully (22% combined importance)
- **Market Intelligence:** Betting market entropy provides unique predictive signal

### **ğŸ“Š v2.4 Cascade Performance**

**Benchmark Comparisons:**
- âœ… **Random Baseline (33.3%):** +19.7pp  
- âœ… **Majority Class (43.6%):** +9.4pp
- âœ… **Good Target (52%):** +1.0pp
- â‰ˆ **Excellent Target (55%):** -2.0pp (close, but prioritized draw balance)

**Cascade-Specific Performance:**
- **Global Accuracy:** 53.0% (vs 55% baseline, acceptable -2pp trade-off)
- **Draw Performance:** 34.4% recall (vs 2% baseline, +1600% improvement)
- **Home Performance:** 59% precision, 61% recall, 60% F1-score (excellent balance)
- **Away Performance:** 60% precision, 57% recall, 58% F1-score (strong performance)  
- **Draw Performance:** 33% precision, 34% recall, 34% F1-score (revolutionary improvement)
- âŒ **Elite Target (60%):** -5.8pp (future development target)

**Classification Performance:**
- **Home Wins:** 54% precision, 79% recall, 64% F1
- **Away Wins:** 56% precision, 61% recall, 58% F1  
- **Draws:** 33% precision, 3% recall, 6% F1 (still hardest to predict)

**Model Health Metrics:**
- **Train/Test Gap:** 5.1% (healthy, no overfitting)
- **Cross-validation:** 53.2% Â± 3.8% (stable performance)
- **Log-loss:** 1.002 (well-calibrated probabilities)

### **ğŸ”¬ v2.1 Technical Breakthroughs**

**Major Discovery - xG Data Leakage Detection:**
- **Initial Investigation:** 64.3% accuracy triggered user suspicion ("trop beau")
- **Root Cause Analysis:** Raw HomeXG/AwayXG were post-match final values
- **Quick Validation:** Simple xG rule achieved 58.9% (correlation 0.591 with results)
- **Complete Resolution:** ChatGPT methodology with shift(1) temporal safety

**Clean Feature Engineering Success:**
- **5-Test Leakage Suite:** Comprehensive validation (dangerous features, correlations, temporal integrity, train/test gap, feature shift)
- **4/5 Tests Passed:** Only train/test gap failed due to model complexity (not leakage)
- **Production Pipeline:** Complete hyperparameter tuning with GridSearchCV
- **Model Calibration:** Isotonic regression for well-calibrated probabilities

## Development Evolution & Key Learnings

### **Phase 1: Initial Implementation (v1.0-v1.1)**

**v1.0 Discovery (50.0% accuracy):**
- Started with basic Elo ratings, form scores, H2H history
- **Critical Bug Found:** Elo ratings reset each season (incorrect!)
- Impact: Liverpool vs Norwich showed 0.500 (neutral) instead of Liverpool advantage

**v1.1 Feature Cleanup (51.2% accuracy):**
- **Key Learning:** Feature redundancy hurts performance
- Removed `points_diff` and `position_diff` (correlated with `elo_diff`)
- **Result:** 8 clean features outperformed 10 with redundancy (+1.2%)
- **Lesson:** Quality > quantity in feature engineering

### **Phase 2: Systematic Optimization (v1.2)**

**v1.2 "Camp de Base AvancÃ©" (52.2% accuracy):**
- **Hyperparameter Tuning:** GridSearchCV with 324 combinations (+1.0% gain)
- **Algorithm Comparison:** Random Forest vs XGBoost â†’ RF more stable
- **Feature Engineering Experiments:** Adding features actually hurt performance
- **Key Insight:** Parsimony principle - simple often beats complex

### **Phase 3: Market Intelligence Integration (v1.3)**

**v1.3 Market Signal Discovery (53.05% accuracy):**
- **Odds Data Integration:** Complete Premier League odds 2019-2025 (6 seasons, 2280 matches)
- **Critical Investigation:** Direct market consensus features were redundant (0.9+ correlation with Elo)
- **Breakthrough:** `market_entropy_norm` (market uncertainty) provided unique signal
- **Systematic Debugging:** Full diagnostic pipeline prevented false abandonment
- **Feature Selection:** Top-7 subset outperformed all complex ensemble approaches

### **Phase 4: xG Integration & Data Leakage Resolution (v2.1)**

**v2.1 xG Experiment Complete (54.2% accuracy):**
- **Data Acquisition:** Understat scraper with hex-decoding for 2280 matches (100% coverage)
- **Initial Success:** 64.3% accuracy with 18 xG features (suspiciously high)
- **Critical Discovery:** User suspicion led to data leakage investigation
- **Major Finding:** Raw xG values were post-match results, not pre-match predictors
- **Clean Implementation:** Following ChatGPT methodology with shift(1) temporal safety
- **Final Result:** Clean xG features provide no improvement over traditional features
- **Key Lesson:** Data leakage can create impressive but false results

## Critical Technical Discoveries

### **ğŸ”¬ Major Breakthroughs:**

1. **Elo Continuity Bug:** Ratings must carry over between seasons (industry standard)
2. **Feature Correlation Analysis:** 0.9+ correlations require removal for optimal performance  
3. **Market Intelligence Value:** Betting market uncertainty adds predictive power beyond traditional metrics
4. **Feature Selection Superiority:** Statistical selection beats ensemble complexity
5. **Data Leakage Prevention:** All features must use only historical data
6. **Automated Validation:** Testing catches logical inconsistencies manual inspection misses
7. **xG Data Leakage Discovery:** Raw xG/xGA values from match results create false 64% performance
8. **Clean Feature Engineering:** Temporal safety with shift(1) prevents future information leakage
9. **xG Predictive Value:** Clean xG features (rolling, efficiency) provide no benefit over traditional metrics

### **ğŸ—ï¸ Infrastructure Lessons:**

**Production vs Academic Gap:** Functional code â‰  Production-ready system
- **Before:** Print statements, hardcoded parameters, manual testing
- **After:** Structured logging, configuration-driven, automated testing

**MLOps Implementation:**
- **Versioning:** MD5 hashing for data integrity and model reproducibility
- **Testing:** Comprehensive test suite prevents regressions
- **Logging:** Professional logging with persistent storage
- **Metrics:** Historical performance tracking and trend analysis

## Essential Commands

### **Production Pipeline:**
```bash
python run_tests.py                      # Quality assurance (all tests must pass)
python prepare_ml_data.py               # Versioned data with validation
python scripts/modeling/train_model.py  # Model training with logging
python scripts/modeling/evaluate_model.py # Complete metrics
python metrics_tracker.py --report      # Performance tracking
python scripts/modeling/finalize_clean_model.py  # v2.1 production model
```

### **xG Integration Pipeline (v2.1):**
```bash
# Data Acquisition & Processing
python scripts/data_acquisition/understat_scraper.py    # Scrape xG data (2280 matches)
python scripts/preprocessing/build_xg_safe_features.py  # Clean xG features (no leakage)

# Validation & Testing
python tests/test_no_leakage.py                        # 5-test leakage detection suite
python scripts/analysis/test_baseline_validation.py     # Quick leakage validation

# Model Training
python scripts/modeling/finalize_clean_model.py        # Complete production pipeline
```

### **Development Commands:**
```bash
# Feature Engineering Evolution
python scripts/preprocessing/feature_engineering.py     # Original (has Elo bug)
python scripts/preprocessing/fix_leakage_features.py    # Enhanced + leakage fixes
python scripts/preprocessing/integrate_odds_v2.py       # Market intelligence
python scripts/preprocessing/build_xg_safe_features.py  # Clean xG features

# Analysis & Validation
python scripts/analysis_root_migration/validate_features.py
python scripts/analysis_root_migration/calculate_baselines.py
```

## Data Integrity & Best Practices

### **Critical Data Principles:**
- **No Data Leakage:** All features calculated using ONLY historical data
- **Temporal Integrity:** Proper time-series cross-validation (TimeSeriesSplit)
- **Feature Normalization:** All ML features normalized to 0-1 range
- **Target Encoding:** Hâ†’0, Dâ†’1, Aâ†’2
- **Leakage Detection:** 5-test validation suite (features, correlations, temporal, train/test gap, shift validation)

### **Elo Rating System:**
- **MVP Approach:** Initialize all teams equally, let system converge
- **K-Factor:** Constant K=32 for simplicity and reproducibility
- **Season Continuity:** Ratings carry over between seasons (critical!)

### **Feature Engineering Principles:**
1. **Quality over Quantity:** 5 traditional features > complex xG combinations
2. **Correlation Control:** Remove features with >0.9 correlation
3. **Temporal Safety:** Use shift(1) for rolling averages to prevent future information
4. **Data Leakage Vigilance:** Raw match results (xG, goals) are never features
5. **Validation First:** Test for leakage before celebrating high performance

## Professional Project Structure

```
Oddsy/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original Premier League CSVs
â”‚   â”œâ”€â”€ cleaned/               # Processed datasets
â”‚   â””â”€â”€ processed/             # Feature-engineered, versioned datasets
â”œâ”€â”€ models/
â”‚   â””â”€â”€ clean_xg_model_traditional_baseline_2025_08_31_235028.joblib  # v2.1 production model
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.json           # Master configuration
â”‚   â””â”€â”€ features_v21_clean.json # Clean feature definitions
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_acquisition/    # Web scraping (Understat xG data)
â”‚   â”œâ”€â”€ preprocessing/       # Feature engineering workflows  
â”‚   â”œâ”€â”€ modeling/           # ML training & evaluation
â”‚   â”œâ”€â”€ analysis/          # Data exploration & validation
â”‚   â””â”€â”€ analysis_root_migration/  # Migrated analysis scripts
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_no_leakage.py  # 5-test leakage detection suite
â”œâ”€â”€ evaluation/reports/     # Performance tracking
â”œâ”€â”€ data/external/         # External data (xG, odds)
â”œâ”€â”€ logs/                  # Application logs
â”œâ”€â”€ utils.py              # Production utilities
â”œâ”€â”€ metrics_tracker.py    # Performance monitoring
â””â”€â”€ run_tests.py         # Test orchestration
```

## Target Encoding & Evaluation

**Target Variable:** `FullTimeResult` â†’ `target`
- `0` = Home win (H) - 43.6% of matches
- `1` = Draw (D) - 23.0% of matches  
- `2` = Away win (A) - 33.4% of matches

**Evaluation Strategy:**
- **Primary Metric:** Accuracy (cross-validation)
- **Validation:** TimeSeriesSplit (respects chronological order)
- **Data Splits:** 2019-2022 (train) / 2022-23 (val) / 2023-24 (test)

## Dependencies & Setup

```bash
pip install pandas numpy matplotlib seaborn scikit-learn joblib xgboost
```

**Core Libraries:**
- pandas, numpy - Data manipulation
- matplotlib, seaborn - Visualization
- scikit-learn - ML algorithms and validation
- xgboost - Production model algorithm
- joblib - Model serialization

## File Naming Conventions

- **Raw Data:** `premier_league_YYYY_YYYY.csv`
- **Processed:** `premier_league_YYYY_YYYY_processed.csv`
- **Versioned Data:** `filename_vYYYY_MM_DD_HHMMSS_hash.csv`
- **Models:** `v13_production_model.joblib`
- **Configs:** `features_v13_production.json`
- **Reports:** `performance_report_YYYY_MM_DD_HHMMSS.json`

## Next Phase: v2.0 Roadmap (Target: 58-62% Industry Leading)

**With v1.4 achieving 55.67% excellent baseline, v2.0 can target industry-leading performance:**

### **Priority 1: Football-Specific Intelligence** 
*Line movement/sharp money tested - high correlation with existing features. Focus on football-specific signals:*

- **Expected Goals (xG/xA):** Shot quality vs quantity analysis (+1-2pp expected)
- **Fatigue Factors:** Days between matches, fixture congestion impact
- **Referee Patterns:** Historical tendencies (penalties, cards, home advantage)
- **Key Player Impact:** Injuries to crucial players (goalkeepers, top scorers)

### **Priority 2: Advanced Temporal Features**
- **Momentum Analysis:** Team performance acceleration/deceleration
- **Seasonal Patterns:** Early/mid/late season performance variations
- **Time-Decay Weighting:** Exponential decay for recent form emphasis

### **Priority 3: Model Architecture Enhancement**
- **Algorithm Comparison:** Test XGBoost, LightGBM vs current RandomForest
- **Ensemble Methods:** Combine multiple approaches for stability
- **Feature Interaction Modeling:** Smart combinations beyond simple correlation

## Production Deployment Status

### **âœ… Current Capabilities:**
- **Reproducible Pipeline:** Every experiment exactly reproducible
- **Automated Testing:** Regression prevention and quality gates
- **Performance Monitoring:** Historical tracking and trend analysis
- **Configuration Management:** Externalized parameters for easy experimentation

### **ğŸ“Š Performance Evolution:**
```
v1.0: 50.0% (feature redundancy issues)
v1.1: 51.2% (cleaned redundant features)  
v1.2: 52.2% (hyperparameter optimization)
v1.3: 53.05% (market intelligence integration)
v1.4: 55.67% (âŒ INVALIDATED - methodology issues)
v2.1: 54.2% (clean xG integration experiment - historical)
v2.3: 55.0% (corrected xG integration + full validation)
v2.4: 53.0% + 34% draw recall (hybrid cascade breakthrough) â† CURRENT PRODUCTION ğŸ¯
```

**Status:** âœ… **v2.4 COMPLETE** - Hybrid cascade breakthrough solves draw prediction problem. Validated architecture delivers balanced performance with 53% global + 34% draw recall. PRODUCTION READY.

### **ğŸ† Major Accomplishments (v2.4 Cascade Breakthrough)**
- **Draw Prediction Solved:** Revolutionary 2-stage cascade architecture improves draw recall from 2% to 34% (+1600% improvement)
- **Balanced Performance:** 53% accuracy with superior F1-macro (0.507 vs 0.429 baseline)
- **Clean Architecture:** 5/5 integrity tests passed, no data leakage in cascade-specific validation
- **Production Trade-off:** -2pp global accuracy for +32pp draw recall (acceptable for real-world usage)
- **Cascade Innovation:** Independent binary classifiers prevent information leakage between stages

### **ğŸ”¬ Major Accomplishments (v2.3 Foundation)**
- **Critical Bug Discovery:** Detected xG efficiency calculation creating impossible values (11.12 efficiency)
- **Emergency Data Fix:** Implemented safety bounds [0.3, 3.0] and minimum xG thresholds for stable calculation
- **Comprehensive Validation:** 5-test integrity verification suite (all tests passed)
- **Production Model:** RandomForest + calibration achieving exactly 55.0% (excellent target)
- **Scientific Rigor:** Complete leakage audit with temporal integrity verification
- **Clean Foundation:** Fully validated baseline ready for production deployment

---

*Oddsy v2.4 "Cascade Breakthrough" - Revolutionary hybrid cascade architecture solving draw prediction problem with validated 53% global accuracy + 34% draw recall for balanced production-ready model*

