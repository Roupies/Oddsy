#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ðŸš€ AmÃ©lioration des Nuls (v1.6) avec SMOTE
Objectif: Augmenter drastiquement le F1-score pour la classe "Draw"
"""
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ML
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, f1_score
from imblearn.over_sampling import SMOTE
import json
import os

print("ðŸŽ¯ v1.6 - AmÃ©lioration des Nuls avec SMOTE")
print("="*60)

# --- 1. CHARGEMENT DES DONNÃ‰ES (MÃ‰THODOLOGIE PROPRE) ---
def load_clean_data():
    """Charge les donnÃ©es avec le split temporel propre."""
    df = pd.read_csv('data/processed/v13_xg_safe_features.csv', parse_dates=['Date'])
    
    # 10 features qui ont bien performÃ©
    optimal_features = [
        'form_diff_normalized', 'elo_diff_normalized', 'h2h_score',
        'matchday_normalized', 'shots_diff_normalized', 'corners_diff_normalized',
        'market_entropy_norm', 'home_xg_eff_10', 'away_goals_sum_5', 'away_xg_eff_10'
    ]
    
    # Split temporel par saison
    train_data = df[df['Date'] <= '2024-05-19'].copy().dropna(subset=optimal_features)
    test_data = df[df['Date'] >= '2024-08-16'].copy().dropna(subset=optimal_features)

    X_train = train_data[optimal_features].fillna(0.5)
    X_test = test_data[optimal_features].fillna(0.5)
    y_train = train_data['FullTimeResult'].map({'H': 0, 'D': 1, 'A': 2})
    y_test = test_data['FullTimeResult'].map({'H': 0, 'D': 1, 'A': 2})
    
    print(f"ðŸ“Š DonnÃ©es prÃªtes: Train={len(X_train)}, Test={len(X_test)}")
    return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = load_clean_data()

# --- 2. ENTRAÃŽNEMENT DU MODÃˆLE DE BASE (SANS SMOTE) ---
print("\n--- Ã‰tape 1: Performance du ModÃ¨le de Base (v1.5) ---")

# Utilisation des meilleurs hyperparamÃ¨tres trouvÃ©s prÃ©cÃ©demment
baseline_params = {
    'n_estimators': 300, 'max_depth': 10, 'min_samples_leaf': 10,
    'min_samples_split': 15, 'max_features': 'log2', 'class_weight': 'balanced',
    'random_state': 42, 'n_jobs': -1
}

baseline_model = RandomForestClassifier(**baseline_params)
baseline_model.fit(X_train, y_train)
y_pred_baseline = baseline_model.predict(X_test)
baseline_accuracy = accuracy_score(y_test, y_pred_baseline)
baseline_f1_draw = f1_score(y_test, y_pred_baseline, average='macro', labels=[1])

print(f"ðŸŽ¯ Accuracy (Baseline): {baseline_accuracy:.4f}")
print("Classification Report (Baseline):")
print(classification_report(y_test, y_pred_baseline, target_names=['Home', 'Draw', 'Away']))


# --- 3. APPLICATION DE SMOTE (LA MAGIE OPÃˆRE ICI) ---
print("\n--- Ã‰tape 2: CrÃ©ation de DonnÃ©es d'EntraÃ®nement Enrichies avec SMOTE ---")

# SMOTE ne s'applique QUE sur les donnÃ©es d'entraÃ®nement pour Ã©viter toute fuite de donnÃ©es
smote = SMOTE(random_state=42, k_neighbors=5)
print(f"Distribution originale (Train): {y_train.value_counts().to_dict()}")

X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
print(f"Distribution aprÃ¨s SMOTE (Train): {y_train_smote.value_counts().to_dict()}")
print("âœ… SMOTE a crÃ©Ã© des exemples synthÃ©tiques pour Ã©quilibrer les classes.")


# --- 4. ENTRAÃŽNEMENT DU MODÃˆLE AMÃ‰LIORÃ‰ (AVEC SMOTE) ---
print("\n--- Ã‰tape 3: Performance du ModÃ¨le AmÃ©liorÃ© avec DonnÃ©es SMOTE ---")

# On utilise un nouveau modÃ¨le avec les mÃªmes excellents hyperparamÃ¨tres
smote_model = RandomForestClassifier(**baseline_params)

# On l'entraÃ®ne sur les donnÃ©es enrichies
smote_model.fit(X_train_smote, y_train_smote)
y_pred_smote = smote_model.predict(X_test)
smote_accuracy = accuracy_score(y_test, y_pred_smote)
smote_f1_draw = f1_score(y_test, y_pred_smote, average='macro', labels=[1])

print(f"ðŸŽ¯ Accuracy (SMOTE): {smote_accuracy:.4f}")
print("Classification Report (SMOTE):")
print(classification_report(y_test, y_pred_smote, target_names=['Home', 'Draw', 'Away']))

# --- 5. COMPARAISON FINALE ---
print("\nðŸ†ðŸ†ðŸ† COMPARAISON FINALE ðŸ†ðŸ†ðŸ†")
print("="*60)
print(f"| MÃ©trique          | Baseline (v1.5) | ModÃ¨le SMOTE (v1.6) | AmÃ©lioration     |")
print(f"|-------------------|-----------------|---------------------|------------------|")
print(f"| Accuracy GÃ©nÃ©rale | {baseline_accuracy:15.2%} | {smote_accuracy:19.2%} | {smote_accuracy - baseline_accuracy:+.2%}            |")
print(f"| F1-Score (Draws)  | {baseline_f1_draw:15.2%} | {smote_f1_draw:19.2%} | {smote_f1_draw - baseline_f1_draw:+.2%} ðŸ”¥ðŸ”¥ðŸ”¥ |")
print("="*60)

if smote_f1_draw > baseline_f1_draw * 1.5 and smote_f1_draw > 0.20:
    print("\nðŸŽ‰ Victoire Totale ! Le F1-score pour les nuls a explosÃ©. C'est une avancÃ©e majeure.")
else:
    print("\nðŸ¤” RÃ©sultat mitigÃ©. SMOTE a aidÃ©, mais il y a encore du travail pour maÃ®triser les nuls.")
